---
title: Webpack에 Sitemap, robots.txt 설정하기
description: 웹팩 플러그인 사용
date: June 8, 2023
---

### 서두 \~갑자기 추가하게 된 이유~

블로그를 개발하는 중, 문득 [이전에 사용하던 블로그](https://lah1203.github.io/)에 아직 들어오는 사람이 있을까 궁금했습니다. 예전에 Google Search Console에 등록해놓은 적이 있기에 들어가 실적 보고서를 봤습니다.

<img width="100%" alt="죽은 블로그 실적 보고서" src="https://github.com/LAH1203/blog/assets/57928612/56acfd62-3465-4898-ba46-632b0084c26b" />

??

죽은 블로그에도 꽤나 많은 클릭이 있었습니다. 22년 3월 이후로 글을 올린 적이 없으니 딱히 볼 글도 없었을텐데,, 🤣

문득 지금 블로그도 구글 서치 콘솔에 등록해놓으면 좋겠다는 생각이 들었습니다.

아마 해보신 분들은 아시겠지만, 등록하고 제대로 관리하기 위해서는 사이트맵과 robots.txt 파일이 필요합니다. 더 정확히는 해당 사이트에서 `.sitemap` 또는 `.sitemap.xml` 같은 사이트맵을 의미하는 링크로 들어갔을 때 사이트맵이 보이고, `robots.txt` 링크로 들어갔을 때 robots.txt 파일의 내용이 보여야하는 것이죠.

저는 이전 블로그는 Jekyll의 테마를 가져다 사용했기 때문에 제가 따로 설정해야할 것은 없었고 자동으로 잘 적용이 됐습니다. 하지만 지금의 블로그는 바닥부터 직접 만든 것이고, 당연히 빌드 파일 내용물에는 사이트맵과 robots.txt는 없었죠. 이에 대한 설정이 필요했습니다.

다행히 저는 다양한 플러그인이나 설정들의 예시 참고를 많이 하고 싶어 번들링 도구로 webpack을 사용하고 있었습니다. 당연히 사이트맵과 관련된 플러그인도 존재했습니다.

<br />

### 사이트맵 설정

사이트맵 추가를 위해 제가 사용한 플러그인은 [sitemap-webpack-plugin](https://www.npmjs.com/package/sitemap-webpack-plugin)입니다. 마지막 업데이트가 무려 2년 전인 제대로 동작하는지조차 의심되는 플러그인이었죠.

사실 사이트맵 파일을 직접 만들어 사용해도 되고, 자동화를 해 빌드 시마다 만들 수도 있지만 저는 우선 간단히 적용해보고 싶었습니다. webpack.config.js 파일에 해당 플러그인을 추가했습니다.

```js
const SitemapPlugin = require('sitemap-webpack-plugin').default;

const paths = [...Array(17)].map((_, idx) => {
  return {
    path: `/post/${idx + 1}`,
    changefreq: 'daily',
    priority: 0.5,
  };
});

module.exports = {
  plugins: [
    new SitemapPlugin({
      base: 'https://lah1203.netlify.app',
      paths,
      options: {
        filename: 'sitemap.xml',
        skipgzip: true,
      },
    }),
  ],
};
```

원하는 path에 대해 changefreq와 priority를 추가하고 이를 map을 사용하여 배열화해 플러그인에 추가해주었습니다. 다만 할 때 당시에 간단하게 하다보니 배열의 길이 설정을 수동으로 수정해주어야 했고, 이는 지금은 조금 불편하다고 생각되어 추후 여력이 된다면 좀 더 편한 방법으로 바꾸고 싶네요ㅎㅎ..

문제 없이 플러그인은 작동했고, 저는 만들어진 [사이트맵](https://lah1203.netlify.app/sitemap.xml)을 콘솔에 등록했습니다.

<br />

### 사이트맵을 주기적으로 가져가지 않는다ㅠㅠ

사실 이 때까지만 해도 robots.txt를 설정해야겠다는 생각은 딱히 없었습니다. 사이트맵을 등록해주었으니 구글봇이 알아서 주기적으로 내 사이트 정보를 가져가주지 않을까? 생각했던 거죠.

근데 이상하게 글이 계속 업데이트되는데도 읽지도 않고 발견된 페이지 수도 늘지가 않습니다.

<img width="100%" alt="사이트맵" src="https://github.com/LAH1203/blog/assets/57928612/34197ead-eefa-4135-9ac0-0fb0ebbd3fdf" />

다른 사람들이 사이트맵을 다시 읽어들여달라고 요청하는 방법도 여러 개 시도해봤지만 소용이 없었습니다. 당연히 제 글은 구글에 검색을 해도 거의 나오지 않았고, 저는 그냥 자기만족용으로 가끔 글을 쓰고 있었습니다.

그러던 중 갑자기 robots.txt가 생각났습니다. 이전 블로그에서는 여기에 사이트맵 위치를 지정하는 부분을 추가했었는데, 혹시 이게 도움이 되지는 않을까 생각한 거죠.

그래서 이번엔 robots.txt 파일을 빌드 파일에 추가하는 방법에 대해 알아봤습니다.

<br />

### robots.txt 설정

가장 처음에 본 플러그인은 [robotstxt-webpack-plugin](https://www.npmjs.com/package/robotstxt-webpack-plugin)이라는 웹팩 플러그인이었습니다. 이 플러그인을 사용해도 문제 없이 robots.txt 파일이 추가됩니다. 다만 robots.txt 파일을 커스텀하고 싶을 때는 [generate-robotstxt](https://www.npmjs.com/package/generate-robotstxt)를 사용하라고 하는데, 이게 원하는대로 잘 동작하지 않았습니다.

그래서 robots.txt는 사이트맵처럼 계속해서 변하지는 않을테니 예전에 폰트나 이미지 같은 정적 애셋을 올리는 데 사용했던 [copy-webpack-plugin](https://www.npmjs.com/package/copy-webpack-plugin)을 사용하기로 합니다.

우선 public 폴더에 robots.txt 파일을 두었습니다.

robots.txt 파일의 내용은 이전 블로그와 동일하게 간단하게 만들었습니다. 딱히 막아야겠다고 생각한 곳도 없었고, 사이트맵에서 필요한 부분은 지정되어 있으니 잘 찾아가겠지 싶었습니다.

```txt
User-agent: *
Allow : /

Sitemap: https://lah1203.netlify.app/sitemap.xml
```

그리고 사이트맵 때와 마찬가지로 webpack.config.js 파일에 robots.txt 파일을 빌드할 때 그대로 복사해오도록 추가했습니다.

```js
const CopyPlugin = require('copy-webpack-plugin');

module.exports = {
  plugins: [
    new CopyPlugin({
      patterns: [{ from: './public/robots.txt', to: 'robots.txt' }],
    }),
  ],
};
```

이렇게 하면 빌드 폴더에 다음과 같이 robots.txt 파일이 잘 추가됩니다.

<img width="40%" alt="빌드 폴더" src="https://github.com/LAH1203/blog/assets/57928612/8233c8da-d8b7-45b1-8648-329281411bb8" />

실제 사이트에서 `/robots.txt` 경로로 들어가도 잘 보여졌습니다.

<br />
<hr />
<br />

일단은 이정도로 마무리하고 며칠 간 구글 서치 콘솔에서 사이트맵을 제대로 가져오는지를 지켜보려고 합니다 👀 만약 안 가져오면... 다시 제 블로그는 자기만족용이 되겠죠 🥲
